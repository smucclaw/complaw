\section{Introduction}\label{sec:introduction}

The goal of this paper is to show how a bottom up ASP reasoner like Clingo can be used for Abductive reasoning over First Order Horn clauses. As mentioned in the abstract previous work in abductive reasoning has mostly focused on implementing abduction in a top-down manner with Prolog as the underlying engine. CIFF \cite{mancarella09:_ciff} is a prominent example of this. More recently sCASP \cite{arias19:_const_answer_set_progr_groun_applic,arias_phd_2019} has been developed as a goal directed ASP implementation that can be used for abduction but this too uses a top down method for query evaluation. However there may be use cases where one wants to know all the resulting consequences of an abductive solution to a query with respect to a rule-set. Also, as mentioned in the abstract, top-down methods can sometimes result in solvers that are not truly declarative. Therefore an abductive reasoner that uses a solver like Clingo \cite{gebser12:_answer_set_solvin_pract} can
complement the abilities of goal directed reasoners like sCASP, CIFF \etc.

This paper shows how, given an input ASP rule set, one can write a new ASP program based on that rule set which will yield abductive solutions to queries, with the input ASP rule set as the background theory. The user does not have to explicitly specify the space of abducibles. This translation from the input ASP rule set to the derived ASP program is a purely mechanical one. The key idea is to encode backward chaining over the input rules through the use of meta predicates which incorporate a notion of 'reversing' the input rules to recursively generate pre-conditions from post conditions thereby generating a maximal space of abducibles. Then having generated this maximal space of abducibles, this 'feeds into' another part of the program where we have a representation of the input rules in the normal 'forward' direction. Entailment of the specified query is then checked via an integrity constraint and a minimal set of abduced facts is returned.

The main technical challenges are dealing with situations where input rules have existential variables in pre-conditions or when the query itself has existential variables. The other challenge is to control the depth of the abducibles generation process. The work that seems to come closest to ours is \cite{schueller16:_model_variat_first_order_horn}. It too uses some similar meta predicates to encode backward chaining, and a forward representation of the rules to check for query entailment via integrity constraints.

However there are several novel features in our work.  Firstly, depth  control for abducible generation is done in a purely declarative way as part of the encoding itself without needing to call external functions or other pieces of software. Furthermore, adding facts to the program automatically gives an implicit form of term substitution where Skolem terms or
other 'place-holder' terms occurring in abducibles are replaced away so that
the resulting proof is simplified, without any need for an explicit representation of equality between terms. Past work on this topic such as \cite{schueller16:_model_variat_first_order_horn} models equality between terms via an explicit equality predicate which may become unwieldy. Another approach to dealing with existential variables encountered during the abductive proof search is to simply ground all the rules over the entire domain of constants. However, this can often lead to too many choices for what an existential variable may be substituted for which may result in unexpected/unintuitive solutions. Our method avoids both of these techniques. We present three main sets of abductive proof generation encodings. One of the encodings only supports partial term substitution whereas the other two support full term substitution. Lastly, we also present an encoding which generates a set of directed edges representing a justification 
graph  for the generated proof, where the graph can be of any desired depth.

The rest of the paper is organised as
follows. First we give a brief introduction to Answer Set Programming and Abductive reasoning then, Section~\ref{sec:abductive_proof} defines the problem being tackled more formally. Section~\ref{sec:derived_asp} presents the encodings that facilitate the abductive proof generation and directed edge generation. The sections that follow discuss some formal results regarding completeness, finiteness of abductive proof generation. We also discuss a formal result regarding term substitution. Finally Section~\ref{sec:conclusion} discusses
future work and concludes.

An extended version of this paper \cite{extended_version} is available from
\emph{arXiv}, containing full proofs and further examples.

\subsection{Answer Set Programming}
Answer Set Programming (ASP) is a declarative language from the logic programming family. It is widely used and studied by knowledge representation and reasoning and symbolic AI researchers for its ability to model common sense reasoning, model combinatorial search problems etc. It incorporates the $\textit{negation-as-failure}$ operator as interpreted under the $\textit{stable model semantics}$. Clingo is a well established implementation of ASP, incorporating additional features such as $\textit{choice rules}$ and optimization statements. We shall only briefly touch upon various aspects of ASP and Clingo here. The reader may consult \cite{gebser12:_answer_set_solvin_pract} for a more thorough description. Each rule in an ASP program consists of a set of body atoms. Some of these body atoms maybe negated via the negation as failure operator $not$. Rules with no pre-conditions are called facts. Given a set of rules $R$ and a set of facts $F$, the Clingo solver computes all stable models of the ASP program $F\cup R$. For example given the fact $r(alpha)$ and the rules:
\begin{lstlisting}[frame=none]
p(X):-r(X),not q(X).
q(X):-r(X), not p(X).
\end{lstlisting}
The solver will show us 2 models or answer sets given by\\ $\{r(alpha),p(alpha)\}$ and $\{r(alpha),q(alpha)\}$. Note that as opposed to Prolog, Clingo is a bottom up solver meaning that it computes complete stable models (also known as answer sets) given any ASP program. An integrity constraint is formally speaking a rule whose post-condition is the boolean $false$. In ASP, integrity constraints are written as rules with no post-conditions and are used to eliminate some computed answer sets. For example given in the following ASP program
\begin{lstlisting}[frame=none]
r(alpha).
p(X):-r(X),not q(X).
q(X):-r(X), not p(X).
:-q(X).
\end{lstlisting}
any answer set where some instantiation of $q$ is true is eliminated. Hence we get just one answer set. $\{r(alpha),p(alpha)\}$.\\ We will now give a quick introduction to two features of Clingo that we will use throughout this paper. Namely $\textit{choice rules}$ and $\textit{weak constraints}$. Weak constraints are also often known as optimization statements. Intuitively a choice rule is a rule where if the pre-conditions are satisfied then the post-condition may or may not be made true. The post-condition of a choice rule is enclosed in curly brackets. So given the following ASP program:\begin{lstlisting}[frame=none]
r(alpha).
{q(X)}:-r(X).
\end{lstlisting}, where the rule is a choice rule the solver will give us 2 models namely $\{r(alpha)\}$, $\{r(alpha),q(alpha)\}$. If we modify the program by adding an integrity constraint like so:
\begin{lstlisting}[frame=none]
r(alpha).
{q(X)}:-r(X).
:-q(X).
\end{lstlisting}
then we get just one model $\{r(alpha)\}$.\\
Weak constraints are used in Clingo to order answer sets by preference according to the atoms that appear in them. Without going into too much detail let us just explain the meaning of one kind of weak constraint which is the only kind that we will use in the paper namely:
\begin{lstlisting}[frame=none]
:~a(X). [1@1,X]
\end{lstlisting}
Adding this to an ASP program, orders the answer sets of the program according to the number of distinct instantiations of the predicate $a$ in the answer set. The answer set with the least number of instantiations of $a$ is called the most $optimal$ answer set. 
\subsection{Abductive Reasoning}
Briefly, abduction is a reasoning process where given a background theory $T$, we wish to find a set of facts $F$ such that $F\cup T$ is consistent and $F\cup T$ entails some goal $g$ for some given entailment relation. Usually we also want $F$ to be minimal in some well defined sense. Traditional Abductive Logic Programming has a long history, but we have our own definitions of what it means to formulate and solve an abductive reasoning problem and we will make all the relevant concepts/notions precise in the sections that follow.  


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
