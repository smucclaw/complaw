
@inproceedings{prakken_logical_1993,
	address = {Amsterdam, The Netherlands},
	title = {A logical framework for modelling legal argument},
	isbn = {978-0-89791-606-6},
	url = {http://portal.acm.org/citation.cfm?doid=158976.158977},
	doi = {10.1145/158976.158977},
	language = {en},
	urldate = {2022-08-27},
	booktitle = {Proceedings of {ICAIL}},
	publisher = {ACM Press},
	author = {Prakken, Henry},
	year = {1993},
	pages = {1--9},
	file = {Prakken - 1993 - A logical framework for modelling legal argument.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\YWEQVP6F\\Prakken - 1993 - A logical framework for modelling legal argument.pdf:application/pdf}
}


@inproceedings{chalkidis_lexglue_2022,
	title = {{LexGLUE}: {A} {Benchmark} {Dataset} for {Legal} {Language} {Understanding} in {English}},
	abstract = {Laws and their interpretations, legal arguments and agreements are typically expressed in writing, leading to the production of vast corpora of legal text. Their analysis, which is at the center of legal practice, becomes increasingly elaborate as these collections grow in size. Natural language understanding (NLU) technologies can be a valuable tool to support legal practitioners in these endeavors. Their usefulness, however, largely depends on whether current state-of-the-art models can generalize across various tasks in the legal domain. To answer this currently open question, we introduce the Legal General Language Understanding Evaluation (LexGLUE) benchmark, a collection of datasets for evaluating model performance across a diverse set of legal NLU tasks in a standardized way. We also provide an evaluation and analysis of several generic and legal-oriented models demonstrating that the latter consistently oﬀer performance improvements across multiple tasks.},
	language = {en},
	booktitle = {Proceedings of {ACL}},
	author = {Chalkidis, Ilias and Jana, Abhik and Hartung, Dirk and Bommarito, Michael and Androutsopoulos, Ion and Katz, Daniel Martin and Aletras, Nikolaos},
	year = {2022},
	pages = {4310--4330},
	file = {Chalkidis et al. - LexGLUE A Benchmark Dataset for Legal Language Un.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\DQ9EMHK7\\Chalkidis et al. - LexGLUE A Benchmark Dataset for Legal Language Un.pdf:application/pdf}
}

@inproceedings{chalkidis_neural_2019,
	address = {Florence, Italy},
	title = {Neural {Legal} {Judgment} {Prediction} in {English}},
	url = {https://www.aclweb.org/anthology/P19-1424},
	doi = {10.18653/v1/P19-1424},
	abstract = {Legal judgment prediction is the task of automatically predicting the outcome of a court case, given a text describing the case’s facts. Previous work on using neural models for this task has focused on Chinese; only featurebased models (e.g., using bags of words and topics) have been considered in English. We release a new English legal judgment prediction dataset, containing cases from the European Court of Human Rights. We evaluate a broad variety of neural models on the new dataset, establishing strong baselines that surpass previous feature-based models in three tasks: (1) binary violation classiﬁcation; (2) multi-label classiﬁcation; (3) case importance prediction. We also explore if models are biased towards demographic information via data anonymization. As a side-product, we propose a hierarchical version of BERT, which bypasses BERT’s length limitation.},
	language = {en},
	urldate = {2021-07-19},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Chalkidis, Ilias and Androutsopoulos, Ion and Aletras, Nikolaos},
	year = {2019},
	pages = {4317--4323},
	file = {Chalkidis et al. - 2019 - Neural Legal Judgment Prediction in English.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\53RSVK8J\\Chalkidis et al. - 2019 - Neural Legal Judgment Prediction in English.pdf:application/pdf}
}

@article{collins_head-driven_2003,
	title = {Head-{Driven} {Statistical} {Models} for {Natural} {Language} {Parsing}},
	volume = {29},
	issn = {0891-2017, 1530-9312},
	url = {https://direct.mit.edu/coli/article/29/4/589-637/1822},
	doi = {10.1162/089120103322753356},
	language = {en},
	number = {4},
	urldate = {2022-08-27},
	journal = {Computational Linguistics},
	author = {Collins, Michael},
	month = dec,
	year = {2003},
	pages = {589--637},
	file = {Collins - 2003 - Head-Driven Statistical Models for Natural Languag.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\6HZHL72V\\Collins - 2003 - Head-Driven Statistical Models for Natural Languag.pdf:application/pdf}
}

@incollection{sartor_akoma-ntoso_2011,
	address = {Dordrecht},
	title = {Akoma-{Ntoso} for {Legal} {Documents}},
	isbn = {978-94-007-1886-9 978-94-007-1887-6},
	url = {http://link.springer.com/10.1007/978-94-007-1887-6},
	language = {en},
	urldate = {2022-08-27},
	booktitle = {Legislative {XML} for the {Semantic} {Web}},
	publisher = {Springer Netherlands},
	author = {Palmirani, Monica and Vitali, Fabio},
	editor = {Sartor, Giovanni and Palmirani, Monica and Francesconi, Enrico and Biasiotti, Maria Angela},
	year = {2011},
	doi = {10.1007/978-94-007-1887-6},
	pages = {75--100},
	file = {Sartor et al. - 2011 - Legislative XML for the Semantic Web.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\MBGESBQF\\Sartor et al. - 2011 - Legislative XML for the Semantic Web.pdf:application/pdf}
}

@inproceedings{athan_oasis_2013,
	address = {Rome, Italy},
	title = {{OASIS} {LegalRuleML}},
	isbn = {978-1-4503-2080-1},
	url = {http://dl.acm.org/citation.cfm?doid=2514601.2514603},
	doi = {10.1145/2514601.2514603},
	abstract = {In this paper we present the motivation, use cases, design principles, abstract syntax, and initial core of LegalRuleML. The LegalRuleMLcore is sufﬁciently rich for expressing legal sources, time, defeasibility, and deontic operators. An example is provided. LegalRuleMLis compared to related work.},
	language = {en},
	urldate = {2022-08-27},
	booktitle = {Proceedings of {ICAIL}},
	publisher = {ACM Press},
	author = {Athan, Tara and Boley, Harold and Governatori, Guido and Palmirani, Monica and Paschke, Adrian and Wyner, Adam},
	year = {2013},
	pages = {3--12},
	file = {Athan et al. - 2013 - OASIS LegalRuleML.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\ZHQ4CMGH\\Athan et al. - 2013 - OASIS LegalRuleML.pdf:application/pdf}
}

@inproceedings{hulstijn_taxonomy_2020,
	title = {A {Taxonomy} for the {Representation} of {Privacy} and {Data} {Control} {Signals}},
	isbn = {978-1-64368-150-4 978-1-64368-151-1},
	url = {http://ebooks.iospress.nl/doi/10.3233/FAIA200846},
	abstract = {In interacting with digital apps and services, users create digital identities and generate massive amounts of associated personal data. The relationship between the user and the service provider in such cases is, inter alia, a principalagent relationship governed by a ‘contract’. This contract is provided mostly in natural language text, however, and remains opaque to users. The need of the hour is multi-faceted documentation represented in machine-readable, natural language and graphical formats, to enable tools such as smart contracts and privacy assistants which could assist users in negotiating and monitoring agreements.},
	language = {en},
	urldate = {2022-08-27},
	booktitle = {Proceedings of {JURIX}},
	publisher = {IOS Press},
	author = {Hulstijn, Joris},
	month = dec,
	year = {2020},
	doi = {10.3233/FAIA200846},
	pages = {23--32},
	file = {Chawla and Hulstijn - 2020 - A Taxonomy for the Representation of Privacy and D.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\84GD57AV\\Chawla and Hulstijn - 2020 - A Taxonomy for the Representation of Privacy and D.pdf:application/pdf}
}

@article{huttner_catala_2022,
	title = {Catala: {Moving} towards the future of legal expert systems},
	issn = {0924-8463, 1572-8382},
	shorttitle = {Catala},
	url = {https://link.springer.com/10.1007/s10506-022-09328-5},
	doi = {10.1007/s10506-022-09328-5},
	abstract = {Around the world, private and public organizations use software called legal expert systems to compute taxes. This software must comply with the laws they are designed to implement. As such, a bug or an error in a program that leads to tax miscalculations can have heavy legal and democratic consequences. However, increasing evidence suggests that some legal expert systems may not comply with the law. Moreover, traditional software development processes mean that legal expert systems are difficult to adapt to the continuous flow of new legislation. To prevent further software decay and to reconcile these systems with the growing demand for algorithmic transparency, we argue that there is a need for a new development process for legal expert systems. This new system must be built to comply with the law, in particular the GDPR. It must also respect democratic transparency. For these reasons, we present a solution built by lawyers and computer scientists: Catala, a new programming language coupled with a pair programming development process.},
	language = {en},
	urldate = {2022-08-27},
	journal = {Artificial Intelligence and Law},
	author = {Huttner, Liane and Merigoux, Denis},
	month = aug,
	year = {2022},
	file = {Huttner and Merigoux - 2022 - Catala Moving towards the future of legal expert.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\WPV3Z4XE\\Huttner and Merigoux - 2022 - Catala Moving towards the future of legal expert.pdf:application/pdf}
}


@article{mccarty_reflections_1977,
	title = {Reflections on "{Taxman}": {An} {Experiment} in {Artificial} {Intelligence} and {Legal} {Reasoning}},
	volume = {90},
	issn = {0017811X},
	shorttitle = {Reflections on "{Taxman}"},
	url = {https://www.jstor.org/stable/1340132?origin=crossref},
	doi = {10.2307/1340132},
	number = {5},
	urldate = {2020-07-15},
	journal = {Harvard Law Review},
	author = {McCarty, L. Thorne},
	month = mar,
	year = {1977},
	pages = {837},
	file = {McCarty - 1977 - Reflections on Taxman An Experiment in Artifici.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\7UD5ZRI9\\McCarty - 1977 - Reflections on Taxman An Experiment in Artifici.pdf:application/pdf}
}


@article{sergot_british_1986,
	title = {The {British} {Nationality} {Act} as a logic program},
	volume = {29},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/5689.5920},
	doi = {10.1145/5689.5920},
	language = {en},
	number = {5},
	urldate = {2022-08-26},
	journal = {Communications of the ACM},
	author = {Sergot, M. J. and Sadri, F. and Kowalski, R. A. and Kriwaczek, F. and Hammond, P. and Cory, H. T.},
	month = may,
	year = {1986},
	pages = {370--386},
	file = {British Nationality Act.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\WIGZG9YE\\British Nationality Act.pdf:application/pdf}
}

@inproceedings{mccarty_language_1989,
	address = {Vancouver, British Columbia, Canada},
	title = {A language for legal {Discourse} {I}. basic features},
	isbn = {978-0-89791-322-5},
	url = {http://portal.acm.org/citation.cfm?doid=74014.74037},
	doi = {10.1145/74014.74037},
	language = {en},
	urldate = {2022-08-26},
	booktitle = {Proceedings of {ICAIL}},
	publisher = {ACM Press},
	author = {McCarty, L. T.},
	year = {1989},
	pages = {180--189},
	file = {McCarty - 1989 - A language for legal Discourse I. basic features.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\H3A87NCD\\McCarty - 1989 - A language for legal Discourse I. basic features.pdf:application/pdf}
}

@inproceedings{witt_converting_2021,
	address = {São Paulo Brazil},
	title = {Converting copyright legislation into machine-executable code: interpretation, coding validation and legal alignment},
	isbn = {978-1-4503-8526-8},
	shorttitle = {Converting copyright legislation into machine-executable code},
	url = {https://dl.acm.org/doi/10.1145/3462757.3466083},
	doi = {10.1145/3462757.3466083},
	language = {en},
	urldate = {2022-08-04},
	booktitle = {Proceedings of the {Eighteenth} {International} {Conference} on {Artificial} {Intelligence} and {Law}},
	publisher = {ACM},
	author = {Witt, Alice and Huggins, Anna and Governatori, Guido and Buckley, Joshua},
	month = jun,
	year = {2021},
	pages = {139--148},
	file = {Full Text:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\J4AWBEVT\\Witt et al. - 2021 - Converting copyright legislation into machine-exec.pdf:application/pdf}
}

@inproceedings{valente_law_1991,
	title = {{LAW} {FUNCTIONS}: {MODELING} {PRINCIPLES} {IN} {LEGAL} {REASONING}},
	abstract = {Within the ESPRIT project KADS-II, a library of interpretation models is currently being developed. To accomplish this task, we have to define a series of ontologies associated to general domains. In this paper, we propose the use of a functional analysis of the law through the use of what we called law functions, and its use as a middle-out approach for the development of the library of interpretation models for the law domain.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {Valente, André and Breuker, Joost},
	year = {1991},
	pages = {40--52},
	file = {Valente and Breuker - LAW FUNCTIONS MODELING PRINCIPLES IN LEGAL REASON.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\G4RZU3SE\\Valente and Breuker - LAW FUNCTIONS MODELING PRINCIPLES IN LEGAL REASON.pdf:application/pdf}
}

@inproceedings{haan_tracs_1992,
	title = {{TRACS}: {A} {SUPPORT} {TOOL} {FOR} {DRAFTING} {AND} {TESTING} {LAW}},
	abstract = {This paper discusses the results of the implementation of a prototype system for the application of traffic law. The problems tackled in this system are the computational complexity of legal reasoning regarding the use of knowledge about the world, and the representation and reasoning with deontic modalities. Testing two paragraphs already rendered several important notes about the design of the traffic law. This paper reveals the experiences and results, and gives directions for further research.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {Haan, N Den},
	year = {1992},
	pages = {63--70},
	file = {Haan - TRACS A SUPPORT TOOL FOR DRAFTING AND TESTING LAW.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\PYMPNMSJ\\Haan - TRACS A SUPPORT TOOL FOR DRAFTING AND TESTING LAW.pdf:application/pdf}
}

@inproceedings{bench-capon_support_1992,
	title = {{SUPPORT} {FOR} {POLICY} {MAKERS}: {PROSPECTS} {FOR} {KNOWLEDGE} {BASED} {SYSTEMS}},
	abstract = {This paper discusses the potential for providing knowledge based support for the task of formulating policy, and determining what legislation is required to implement the policy. From a discussion of previous work in this area, certain major obstacles are identified. Chief among these is the need to match what the KBS can do with the way in which policy makers conceptualise and perform their task. Effective support can only be provided by a system which can be fully integrated into the working practice of its users. Some examples of an alternative approach, based on hypertext, are discussed, and some proposals for overcoming the obstacles with a combination of the hypertext and knowledge based approaches are given.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {Bench-Capon, T J M},
	year = {1992},
	pages = {41--50},
	file = {Bench-Capon - SUPPORT FOR POLICY MAKERS PROSPECTS FOR KNOWLEDGE.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\K23FUMZR\\Bench-Capon - SUPPORT FOR POLICY MAKERS PROSPECTS FOR KNOWLEDGE.pdf:application/pdf}
}

@inproceedings{groendijk_neural_1992,
	title = {{NEURAL} {SCHEMATA} {IN} {AUTOMATED} {JUDICIAL} {PROBLEM} {SOLVING}},
	abstract = {In most contemporary legal knowledge based systems, conclusions are reached by applying rules to case descriptions. A case description usually consists of a limited set of facts. In human judicial problem solving, the application of legal rules is not based on the facts directly, but on a structured interpretation of these raw data. A structured data interpretation serves as a guide through the problem space; it enables the problem solver to ask context sensitive questions and to make plausible default assignments. In this paper, a neural method to create structured data interpretations is advocated and a method to integrate these networks with a rule based system is presented.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {Groendijk, C},
	year = {1992},
	pages = {147--157},
	file = {Groendijk - NEURAL SCHEMATA IN AUTOMATED JUDICIAL PROBLEM SOLV.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\7T8NVBWF\\Groendijk - NEURAL SCHEMATA IN AUTOMATED JUDICIAL PROBLEM SOLV.pdf:application/pdf}
}

@inproceedings{bench-capon_logic_1987,
	address = {Boston, Massachusetts, United States},
	title = {Logic programming for large scale applications in law: {A} formalisation of supplementary benefit legislation},
	isbn = {978-0-89791-230-3},
	shorttitle = {Logic programming for large scale applications in law},
	url = {http://portal.acm.org/citation.cfm?doid=41735.41757},
	doi = {10.1145/41735.41757},
	language = {en},
	urldate = {2022-08-10},
	booktitle = {Proceedings of the first international conference on {Artificial} intelligence and law  - {ICAIL} '87},
	publisher = {ACM Press},
	author = {Bench-Capon, T. J. M. and Robinson, G. O. and Routen, T. W. and Sergot, M. J.},
	year = {1987},
	pages = {190--198},
	file = {Bench-Capon et al. - 1987 - Logic programming for large scale applications in.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\YYGFX89M\\Bench-Capon et al. - 1987 - Logic programming for large scale applications in.pdf:application/pdf}
}

@inproceedings{bing_designing_1987,
	address = {Boston, Massachusetts, United States},
	title = {Designing text retrieval systems for conceptual searching},
	isbn = {978-0-89791-230-3},
	url = {http://portal.acm.org/citation.cfm?doid=41735.41741},
	doi = {10.1145/41735.41741},
	language = {en},
	urldate = {2022-08-10},
	booktitle = {Proceedings of {ICAIL}},
	publisher = {ACM Press},
	author = {Bing, J.},
	year = {1987},
	pages = {43--51},
	file = {Bing - 1987 - Designing text retrieval systems for conceptual se.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\8VUSFBDT\\Bing - 1987 - Designing text retrieval systems for conceptual se.pdf:application/pdf}
}

@inproceedings{svensson_expertisze_1992,
	title = {{EXPERTISZE}, {A} {TOOL} {FOR} {DETERMINING} {THE} {EFFECTS} {OF} {SOCIAL} {SECURITY} {LEGISLATION}},
	abstract = {Social security legislation plays an important role in the Dutch society. In view of this, the effects of social security legislation have to be analysed carefully before new legislation can be made. Due to the growing complexity of legislation on the social security domain, this analysis has become a demanding task. ExpertiSZe is a knowledge-based system developed to support the process of analysing juridical and socio-economic effects of social security legislation. The ExpertiSZe system consists of three modules: a consultation module, a consistency module and a simulation module. These modules, which all work on the basis of the same rule-based model, provide the legislator with more insight into the impact of legislation. This article describes the potential of ExpertiSZe to support the analysis of effects of legislation.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {Svensson, J S and Kordelaar, P J M and Wassink, J G J},
	year = {1992},
	pages = {51--61},
	file = {Svensson et al. - EXPERTISZE, A TOOL FOR DETERMINING THE EFFECTS OF.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\BN5PCRZC\\Svensson et al. - EXPERTISZE, A TOOL FOR DETERMINING THE EFFECTS OF.pdf:application/pdf}
}

@inproceedings{kralingen_norm_1993,
	title = {{NORM} {FRAMES} {IN} {THE} {REPRESENTATION} {OF} {LAWS}},
	abstract = {In this paper we introduce an intermediate frame language for the representation of legal knowledge. The frame language is based on the concept of a norm as a coherent entity in the legal domain. The aim of this article is to show that the norm-frame representation method offers a fertile approach to the representation of legal knowledge. Moreover, this contribution also treats the possibility to use the ideas behind norm frames in the drafting of legislation.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {Kralingen, Robert Van and Oskamp, Eduard},
	year = {1993},
	pages = {11--21},
	file = {Kralingen and Oskamp - NORM FRAMES IN THE REPRESENTATION OF LAWS.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\EBG23NLM\\Kralingen and Oskamp - NORM FRAMES IN THE REPRESENTATION OF LAWS.pdf:application/pdf}
}

@inproceedings{den_haan_constructing_1996,
	title = {{CONSTRUCTING} {NORMATIVE} {RULES}},
	booktitle = {Proceedings of {JURIX}},
	author = {den Haan, Nienke and Breuker, Joost},
	year = {1996},
	pages = {135--147},
	file = {constructing-normative-rules.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\T2QBUDIE\\constructing-normative-rules.pdf:application/pdf}
}

@inproceedings{winkels_automatic_2012,
	title = {Automatic {Extraction} of {Legal} {Concepts} and {Definitions}},
	abstract = {In this paper we present the results of an experiment in automatic concept and definition extraction from written sources of law using relatively simple natural language and standard semantic web technology. The software was tested on six laws from the tax domain.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {Winkels, Radboud and Hoekstra, Rinke},
	year = {2012},
	pages = {157--166},
	file = {Winkels and Hoekstra - Automatic Extraction of Legal Concepts and Definit.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\SX23QU8B\\Winkels and Hoekstra - Automatic Extraction of Legal Concepts and Definit.pdf:application/pdf}
}

@inproceedings{de_maat_automatic_2008,
	title = {Automatic {Classification} of {Sentences} in {Dutch} {Laws}},
	abstract = {The work described here builds on [1], where we presented a categorisation of norms or provisions in legislation. We claimed that the categories are characterized by the use of typical sentence structures and that this would enable automatic detection and classification. In this paper we present the results of experiments in such automatic classification of provisions. We have defined fourteen different categories of provisions, and compiled a list of 81 sentence structures for those categories from twenty Dutch laws. Based on these structures, a parser was used to classify the sentences in fifteen different Dutch laws, classifying 94\% of 476 sentences correctly. It compares well with other, statistical approaches. An important improvement of our classifier will be the distinction of principal and auxiliary sentences.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {de Maat, Emile and Winkels, Radboud},
	year = {2008},
	pages = {207--216},
	file = {de Maat and Winkels - Automatic Classification of Sentences in Dutch Law.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\MQJHW8KF\\de Maat and Winkels - Automatic Classification of Sentences in Dutch Law.pdf:application/pdf}
}

@inproceedings{brighi_towards_2008,
	title = {Towards {Semantic} {Interpretation} of {Legal} {Modiﬁcations} through {Deep} {Syntactic} {Analysis}},
	abstract = {We are concerned with the automatic semantic interpretation of legal modiﬁcatory provisions. We propose a novel approach which pairs deep syntactic parsing and a ﬁne-grained taxonomy of legal modiﬁcations. Although still in a developmental stage, the implemented system can be used to annotate with metainformation modiﬁcatory provisions of NormaInRete documents.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {Brighi, Raffaella and Lesmo, Leonardo and Mazzei, Alessandro and Palmirani, Monica and Radicioni, Daniele P},
	year = {2008},
	pages = {202--206},
	file = {Brighi et al. - Towards Semantic Interpretation of Legal Modiﬁcati.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\424KZPG3\\Brighi et al. - Towards Semantic Interpretation of Legal Modiﬁcati.pdf:application/pdf}
}

@inproceedings{hickey_gdpr_2021,
	title = {A {GDPR} {International} {Transfer} {Compliance} {Framework} {Based} on an {Extended} {Data} {Privacy} {Vocabulary} ({DPV})},
	isbn = {978-1-64368-252-5 978-1-64368-253-2},
	url = {https://ebooks.iospress.nl/doi/10.3233/FAIA210332},
	abstract = {This paper describes a tool using an extended Data Privacy Vocabulary (the DPV) to audit and monitor GDPR compliance of international transfers of personal data. New terms were identified which have been proposed as extensions to the DPV W3C Working Group. A prototype software tool was built based on the model plus a set of validation rules, and synthetic use-cases created to test the capabilities of the model and tool (together a compliance framework). This framework was created because the rules around international transfer compliance are complex and changing, there is an absence of a common approach to ensuring compliance, few tools exist to assist, and those that do lack interoperability. Evaluation results demonstrate that the proposed model improves compliance identification and standardisation. The tool received positive feedback from the data protection practitioners who participated in the evaluation, and an initial version of is now in use in one financial services organisation. While currently the tool only addresses international transfers, in theory the framework can be extended through further work to the broader area of compliance of other aspects of the GPDR.},
	language = {en},
	urldate = {2022-08-16},
	booktitle = {Proceedings of {JURIX}},
	publisher = {IOS Press},
	author = {Hickey, David and Brennan, Rob},
	month = dec,
	year = {2021},
	doi = {10.3233/FAIA210332},
	pages = {161--170},
	file = {Hickey and Brennan - 2021 - A GDPR International Transfer Compliance Framework.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\UDEZESG6\\Hickey and Brennan - 2021 - A GDPR International Transfer Compliance Framework.pdf:application/pdf}
}

@inproceedings{wardika_analyze_2021,
	title = {Analyze the {Usage} of {Legal} {Definitions} in {Indonesian} {Regulation} {Using} {Text} {Mining} {Case} {Study}: {Treasury} and {Budget} {Law}},
	isbn = {978-1-64368-252-5 978-1-64368-253-2},
	shorttitle = {Analyze the {Usage} of {Legal} {Definitions} in {Indonesian} {Regulation} {Using} {Text} {Mining} {Case} {Study}},
	url = {https://ebooks.iospress.nl/doi/10.3233/FAIA210324},
	abstract = {Legal deﬁnitions are an integral part of legal drafting practice to understand legal documents easily and prevent ambiguity. This research aims to describe how legal deﬁnitions are used among regulations in the domain of Indonesian Treasury and Budget. Simple text mining techniques are used to perform and deliver the process. We extracted deﬁnitions from more than 1.362 related regulations enacted through the period 2003-2020. We found that legal deﬁnitions were used in many variations which may lead to inconsistencies.},
	language = {en},
	urldate = {2022-08-17},
	booktitle = {Proceedings of {JURIX}},
	publisher = {IOS Press},
	author = {Wardika, Fitria Ratna and Mudana Putra, Putu Jasprayana and Paramartha, I Gede Yudi},
	month = dec,
	year = {2021},
	doi = {10.3233/FAIA210324},
	pages = {107--112},
	file = {Amaludin et al. - 2021 - Analyze the Usage of Legal Definitions in Indonesi.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\6JHHTJRF\\Amaludin et al. - 2021 - Analyze the Usage of Legal Definitions in Indonesi.pdf:application/pdf}
}

@inproceedings{palmirani_modelling_2018,
	title = {Modelling {Legal} {Knowledge} for {GDPR} {Compliance} {Checking}},
	abstract = {In the last fifteen years, Semantic Web technologies have been successfully applied to the legal domain. By composing all those techniques and theoretical methods, we propose an integrated framework for modelling legal documents and legal knowledge to support legal reasoning, in particular checking compliance. This paper presents a proof-of-concept applied to the GDPR domain, with the aim to detect infringements of privacy compulsory norms or to prevent possible violations using BPMN and Regorous engine.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {Palmirani, Monica and Governatori, Guido},
	year = {2018},
	pages = {101--110},
	file = {Palmirani and Governatori - Modelling Legal Knowledge for GDPR Compliance Chec.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\TE3BGD2L\\Palmirani and Governatori - Modelling Legal Knowledge for GDPR Compliance Chec.pdf:application/pdf}
}

@inproceedings{palmirani_legal_2018,
	title = {Legal {Ontology} for {Modelling} {GDPR} {Concepts} and {Norms}},
	abstract = {This paper introduces PrOnto, the privacy ontology that models the GDPR main conceptual cores: data types and documents, agents and roles, processing purposes, legal bases, processing operations, and deontic operations for modelling rights and duties. The explicit goal of PrOnto is to support legal reasoning and compliance checking by employing defeasible logic theory (i.e., the LegalRuleML standard and the SPINDle engine).},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {Palmirani, Monica and Martoni, Michele and Rossi, Arianna and Robaldo, Livio},
	year = {2018},
	pages = {91--100},
	file = {Palmirani et al. - Legal Ontology for Modelling GDPR Concepts and Nor.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\9VDJASSJ\\Palmirani et al. - Legal Ontology for Modelling GDPR Concepts and Nor.pdf:application/pdf}
}

@inproceedings{nazarenko_pragmatic_2021,
	title = {A {Pragmatic} {Approach} to {Semantic} {Annotation} for {Search} of {Legal} {Texts} – {An} {Experiment} on {GDPR}},
	isbn = {978-1-64368-252-5 978-1-64368-253-2},
	url = {https://ebooks.iospress.nl/doi/10.3233/FAIA210313},
	abstract = {Tools must be developed to help draft, consult, and explore textual legal sources. Between statistical information retrieval and the formalization of textual rules for automated legal reasoning, we defend a more pragmatic third way that enriches legal texts with a coarse-grained, interpretation-neutral, semantic annotation layer. The aim is that legal texts can be enriched on a large scale at a reasonable cost, paving the way for new search capabilities that will facilitate mining of legal sources. This new approach is illustrated on a proof-of-concept experiment that consisted in semantically annotating a signiﬁcant part of the French version of the GDPR. The paper presents the design methodology of the annotation language, a ﬁrst version of a Core Legal Annotation Language (CLAL), together with its formalization in XML, the gold standard resulting from the annotation of GDPR, and examples of user questions that can be better answered by semantic than by plain text search. This experimentation demonstrates the potential of the proposed approach and provides a basis for further development. All resources developed for that GDPR experiment are language independent and are publicly available.},
	language = {en},
	urldate = {2022-08-17},
	booktitle = {Proceedings of {JURIX}},
	publisher = {IOS Press},
	author = {Nazarenko, Adeline and Lévy, François and Wyner, Adam},
	month = dec,
	year = {2021},
	doi = {10.3233/FAIA210313},
	pages = {23--32},
	file = {Nazarenko et al. - 2021 - A Pragmatic Approach to Semantic Annotation for Se.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\LKFYZ4WE\\Nazarenko et al. - 2021 - A Pragmatic Approach to Semantic Annotation for Se.pdf:application/pdf}
}

@inproceedings{quaresma_question_2005,
	title = {A {Question} {Answer} {System} for {Legal} {Information} {Retrieval}},
	abstract = {In this paper we present a question-answering system for Portuguese juridical documents. The system has two modules: preliminary analysis of documents (information extraction) and query processing (information retrieval). The proposed approach is based on computational linguistic theories: syntactical analysis (constraint grammars); followed by semantic analysis using the discourse representation theory; and, ﬁnally, a semantic/pragmatic interpretation using ontologies and logical inference.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {Quaresma, Paulo and Rodrigues, Irene Pimenta},
	year = {2005},
	pages = {91--100},
	file = {Quaresma and Rodrigues - A Question Answer System for Legal Information Ret.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\S83Y9IE2\\Quaresma and Rodrigues - A Question Answer System for Legal Information Ret.pdf:application/pdf}
}

@inproceedings{mochales_study_2008,
	title = {Study on the {Structure} of {Argumentation} in {Case} {Law}},
	abstract = {This paper investigates natural-language argumentation in the case law domain. The starting point is a study on the discoursive and argumentative characteristiques of ten legal documents from the European Court of Human Rights (ECHR). Then, a generalization of this study allows to formalize the structure of argumentation in the ECHR documents as a context-free grammar. The paper concludes with the evaluation of the grammar and a discussion of its main limitations.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {Mochales, Raquel and Moens, Marie-Francine},
	year = {2008},
	pages = {11--20},
	file = {Mochales and Moens - Study on the Structure of Argumentation in Case La.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\D25B7CFX\\Mochales and Moens - Study on the Structure of Argumentation in Case La.pdf:application/pdf}
}

@inproceedings{bacci_proposal_2013,
	title = {A {Proposal} for {Introducing} the {ECLI} {Standard} in the {Italian} {Judicial} {Documentary} {System}},
	abstract = {In this paper the activities for introducing the ECLI standard in the Italian judicial documentary system are described. Firstly, the speciﬁcations of ECLI for Italian case-law are proposed. Then, the ECLI implementation activities at the Court of Milan as a pilot case are illustrated, in particular a parsing strategy, based on regular expressions, able to detect case law citations, extract the metadata used by the ECLI grammar (typically used in citations) and providing automatic annotation of the references by the ECLI of the target documents.},
	language = {en},
	booktitle = {Proceedings of {ICAIL}},
	author = {Bacci, Lorenzo and Francesconi, Enrico and Sagri, Maria Teresa},
	year = {2013},
	pages = {49--58},
	file = {Bacci et al. - A Proposal for Introducing the ECLI Standard in th.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\WV559QL2\\Bacci et al. - A Proposal for Introducing the ECLI Standard in th.pdf:application/pdf}
}

@inproceedings{wyner_study_2013,
	title = {A {Study} on {Translating} {Regulatory} {Rules} from {Natural} {Language} to {Defeasible} {Logic}},
	abstract = {Legally binding regulations are expressed in natural language. Yet, we cannot formally or automatically reason with regulations in that form. Defeasible Logic has been used to formally represent the semantic interpretation of regulations; such representations may provide the abstract speciﬁcation for a machinereadable and processable representation as in LegalRuleML. However, manual translation is prohibitively costly in terms of time, labour, and knowledge. The paper discusses work in progress using the state-of-the-art in automatic translation of a sample of regulatory clauses to a machine readable formal representation and a comparison to correlated Defeasible Logic representations. It outlines some key problems and proposes tasks to address the problems.},
	language = {en},
	booktitle = {Proceedings of the 7th {International} {Web} {Rule} {Symposium}},
	author = {Wyner, Adam and Governatori, Guido},
	year = {2013},
	pages = {16.1--16.8},
	file = {Wyner and Governatori - A Study on Translating Regulatory Rules from Natur.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\EC8DVY6L\\Wyner and Governatori - A Study on Translating Regulatory Rules from Natur.pdf:application/pdf}
}

@inproceedings{vo_translating_2014,
	address = {Berlin, Heidelberg},
	title = {Translating {Simple} {Legal} {Text} to {Formal} {Representations}},
	volume = {9067},
	isbn = {978-3-662-48118-9 978-3-662-48119-6},
	url = {https://link.springer.com/10.1007/978-3-662-48119-6_19},
	abstract = {Various logical representations and frameworks have been proposed for reasoning with legal information. These approaches assume that the legal text has already been translated to the desired formal representation. However, the approaches for translating legal text into formal representations have mostly focused on inferring facts from text or translating it to a single representation. In this work, we use the NL2KR system to translate legal text into a wide variety of formal representations. This will enable the use of existing logical reasoning approaches on legal text(English), thus allowing reasoning with text.},
	language = {en},
	urldate = {2022-08-17},
	booktitle = {Proceedings of {JSAI}},
	publisher = {Springer Berlin Heidelberg},
	author = {Vo, Nguyen H. and Kashihara, Kazuaki and Baral, Chitta},
	year = {2014},
	doi = {10.1007/978-3-662-48119-6_19},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {259--273},
	file = {Gaur et al. - 2015 - Translating Simple Legal Text to Formal Representa.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\BV2R75VS\\Gaur et al. - 2015 - Translating Simple Legal Text to Formal Representa.pdf:application/pdf}
}

@incollection{cyras_multiphase_2013,
	address = {Frankfurt},
	title = {Multiphase {Transformation} in the {Legal} {Text}-to-{Program} {Approach}},
	abstract = {The paper explores the building of a bridge between legal texts and their representations in computers. We believe that the path connecting the legal text to logic programming requires intermediate steps. Thus an approach in legal informatics is identified which is called Multiphase Transformation (MuPT). Intermediaries are important, as additional goals can be revealed. We use the multiarch bridge metaphor as a form of knowledge visualization. Here symbolization precedes strict mathematical formalizations; the latter are set aside for the future. The paper is inspired by the work of Ken Satoh et al. who translated the Japanese Presupposed Ultimate Fact Theory (the JUF theory) into logic programming. We can characterize JUF as a ‘one-bridge’ theory. We present reflections on law as a whole, whereas the JUF theory specifically concerns civil law.},
	language = {en},
	booktitle = {Libor {Amicorum} {Guido} {Tsuno}},
	publisher = {Vico},
	author = {Čyras, Vytautas and Lachmayer, Friedrich},
	editor = {Sturm, Fritz and Thomas, Philip and Jochen, Otto and Mori, Hikaru},
	year = {2013},
	pages = {57--70},
	file = {Čyras and Lachmayer - Multiphase Transformation in the Legal Text-to-Pro.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\J4U4Z4WV\\Čyras and Lachmayer - Multiphase Transformation in the Legal Text-to-Pro.pdf:application/pdf}
}

@inproceedings{nazarenko_towards_2016,
	title = {Towards a {Methodology} for {Formalizing} {Legal} {Texts} in {LegalRuleML}},
	abstract = {It is well recognised that it is difﬁcult to make the semantic content of legal texts machine readable. We propose a systematic methodology to begin to render a sample legal text into LegalRuleML, which is a proposed markup for legal rules. We propose three levels - coarse, medium, and ﬁne-grained analyses - each of which is compatible with LegalRuleML and which facilitate development from text to formal LegalRuleML. This paper provides guidelines for a coarse-grained analysis, highlighting some of the challenges to address even at this level.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	publisher = {IOS Press},
	author = {Nazarenko, Adeline and Levy, Francois and Wyner, Adam},
	year = {2016},
	pages = {149--154},
	file = {Nazarenko et al. - Towards a Methodology for Formalizing Legal Texts.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\QN4JCN8W\\Nazarenko et al. - Towards a Methodology for Formalizing Legal Texts.pdf:application/pdf}
}

@inproceedings{grabmair_towards_2005,
	title = {Towards {Modeling} {Systematic} {Interpretation} of {Codiﬁed} {Law}},
	abstract = {This short paper introduces the Interaction Predicate model, which attempts to model some aspects of systematic interpretation of codiﬁed law. It introduces an intermediate rule representation containing dynamic reasoning elements which make use of domain knowledge ontologies.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	publisher = {IOS Press},
	author = {Grabmair, Matthias and Ashley, Kevin D},
	year = {2005},
	pages = {107--108},
	file = {Grabmair and Ashley - Towards Modeling Systematic Interpretation of Codi.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\Q2H9IZGH\\Grabmair and Ashley - Towards Modeling Systematic Interpretation of Codi.pdf:application/pdf}
}

@inproceedings{satoh_translating_2009,
	title = {Translating the {Japanese} {Presupposed} {Ultimate} {Fact} {Theory} into {Logic} {Programming}},
	abstract = {The Japanese “theory of presupposed ultimate facts” (called “Yokenjijitsu-ron” in Japanese) for interpreting the Japanese civil code has been underway for over forty years mainly by judges in the Japanese Legal Training Institute, but not yet formalized in a mathematical way. This paper attempts to mathematically formalize this theory and presents the correspondence between the theory and logic programming with “negation as failure”. It is quite surprising that Japanese judges independently developed such a theory without knowing about logic programming.},
	language = {en},
	booktitle = {Proceedings of {JURIX}},
	author = {Satoh, Ken and Kubota, Masahiro and Nishigai, Yoshiaki and Takano, Chiaki},
	year = {2009},
	pages = {162--171},
	file = {Satoh et al. - Translating the Japanese Presupposed Ultimate Fact.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\RAIZM9NR\\Satoh et al. - Translating the Japanese Presupposed Ultimate Fact.pdf:application/pdf}
}

@inproceedings{mccarty_deep_2007,
	title = {Deep semantic interpretations of legal texts},
	abstract = {One of the main obstacles to progress in the field of artificial intelligence and law is the natural language barrier, but the technology of natural language processing has advanced recently. In this paper, we will show that a state-of-the-art statistical parser can handle even the complex syntactic constructions of an appellate court judge, and that a deep semantic interpretation of the full text of a judicial opinion can be computed automatically from the output of the parser. Our ultimate goal is to use this semantic interpretation to extract from a judicial opinion precisely the information that a lawyer wants to know about a case.},
	booktitle = {Proceedings of {ICAIL}},
	author = {McCarty, L. Thorne},
	year = {2007},
	doi = {10.1145/1276318.1276361},
	note = {Journal Abbreviation: Proceedings of the International Conference on Artificial Intelligence and Law
Pages: 224
Publication Title: Proceedings of the International Conference on Artificial Intelligence and Law},
	pages = {217--224},
	file = {McCarty - 2007 - Deep semantic interpretations of legal texts.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\QAJ3YXC4\\McCarty - 2007 - Deep semantic interpretations of legal texts.pdf:application/pdf}
}

@article{lesmo_tulsi_2013,
	title = {{TULSI}: an {NLP} system for extracting legal modificatory provisions},
	volume = {21},
	issn = {0924-8463, 1572-8382},
	shorttitle = {{TULSI}},
	url = {http://link.springer.com/10.1007/s10506-012-9127-6},
	doi = {10.1007/s10506-012-9127-6},
	abstract = {In this work we present the TULSI system (so named after Turin University Legal Semantic Interpreter), a system to produce automatic annotations of normative documents through the extraction of modiﬁcatory provisions. TULSI relies on a deep syntactic analysis and a shallow semantic interpreter that are illustrated in detail. We report the results of an experimental evaluation of the system and discuss them, also suggesting future directions for further improvement.},
	language = {en},
	number = {2},
	urldate = {2022-08-24},
	journal = {Artificial Intelligence and Law},
	author = {Lesmo, Leonardo and Mazzei, Alessandro and Palmirani, Monica and Radicioni, Daniele P.},
	month = may,
	year = {2013},
	pages = {139--172},
	file = {Lesmo et al. - 2013 - TULSI an NLP system for extracting legal modifica.pdf:C\:\\Users\\jerroldsoh\\Juris-M\\storage\\RXYS28Y4\\Lesmo et al. - 2013 - TULSI an NLP system for extracting legal modifica.pdf:application/pdf}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% GF references from this line and below

@article{chomsky-1956,
 author = {N. Chomsky},
 title = {{Three models for the description of language}},
 journal = {{IRE Transactions on Information Theory}},
 volume = {2},
 year = {1956},
 pages = {113--124},
 }


@BOOK{geach-1962,
    AUTHOR = "Geach, Peter",
    TITLE = "Reference and Generality",
    PUBLISHER = {Cornell University Press},
    ADDRESS = {Ithaca, New York},
    YEAR = {1962} }

@INCOLLECTION{kamp-1981,
    AUTHOR = "Kamp, Hans",
    TITLE = "A Theory of Truth and Semantic Representation",
    EDITOR = "J. Groenendijk and T. Janssen and M. Stokhof",
    BOOKTITLE = "Formal Methods in the Study of Language, Part 1",
    PUBLISHER = {Mathematisch Centrum},
    ADDRESS = {Amsterdam},
    YEAR = {1981},
    PAGES = {277-322}}


@inproceedings{perera-ranta-2007,
  title = {{Dialogue System Localization with the GF Resource Grammar Library}},
  author = {N. Perera and A. Ranta},
  booktitle = {{SPEECHGRAM 2007: ACL Workshop on Grammar-Based Approaches to Spoken
   Language Processing, June 29, 2007, Prague}},
  year = {2007}
}

@Book{ranta-2011,
  author = {A. Ranta},
  title =  {{Grammatical Framework:
             Programming with Multilingual Grammars}},
  publisher = {{CSLI Publications}},
  year = {2011},
  address = "Stanford",
}

@inproceedings{fuchs-al-2008,
	author = {Norbert E. Fuchs and Kaarel Kaljurand and Tobias Kuhn},
	title = {{Attempto Controlled English for Knowledge Representation}},
	booktitle = {{Reasoning Web, Fourth International Summer School 2008}},
	editor = {Cristina Baroglio and Piero A. Bonatti and Jan Ma{\l}uszy\'nski and Massimo Marchiori and Axel Polleres and Sebastian Schaffert},
	series = lncs,
	number = {5224},
	publisher = {Springer},
	pages = {104--124},
	year = {2008},
}

@inproceedings{angelov-ranta-2009,
	 AUTHOR = {K. Angelov and A. Ranta},
	 TITLE = {{Implementing Controlled Languages in GF}},
	 BOOKTITLE = {{CNL-2009,
                       Controlled Natural Language Workshop, Marettimo, Sicily, 2009}},
	 YEAR = {2009}
 }

 @article{ranta-2009,
  author = {A. Ranta},
  title = {{The GF Resource Grammar Library}},
  year = 2009,
  journal = {{Linguistics in Language Technology}},
  volume = {2}
}

@InProceedings{ranta-2011c,
author="Ranta, Aarne",
editor="Bj{\o}rner, Nikolaj
and Sofronie-Stokkermans, Viorica",
title="Translating between Language and Logic: What Is Easy and What Is Difficult",
booktitle="Automated Deduction -- CADE-23",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="5--25",
abstract="Natural language interfaces make formal systems accessible in informal language. They have a potential to make systems like theorem provers more widely used by students, mathematicians, and engineers who are not experts in logic. This paper shows that simple but still useful interfaces are easy to build with available technology. They are moreover easy to adapt to different formalisms and natural languages. The language can be made reasonably nice and stylistically varied. However, a fully general translation between logic and natural language also poses difficult, even unsolvable problems. This paper investigates what can be realistically expected and what problems are hard.",
isbn="978-3-642-22438-6"
}

@Misc{gdpr-2018,
  author =       {Digital~Grammars and Signatu},
  title =        {{GDPR Lexicon}},
  howpublished = {\url{https://gdprlexicon.com/}},
  year =         {2018}
}

@article{angelov-al-2013,
  author = {Krasimir Angelov and John Camilleri and Gerardo Schneider},
  title = "A framework for conflict analysis of normative texts written in controlled natural language",
  journal = "The Journal of Logic and Algebraic Programming",
  volume = {82},
  pages = {216--240},
  year = {2013}
  }
